{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6jUHsGGs0Hw",
        "outputId": "2411df44-34d7-45fe-bd00-554158d183f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.921\n",
            "Precision: 0.916548097763976\n",
            "ROC AUC: 0.8687372847678191\n",
            "R1-score: 0.921\n",
            "Best Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
            "Training Completed and Model Saved as Address_Validator_Model.pkl\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "import regex as re\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, roc_curve, auc, recall_score\n",
        "\n",
        "# Load the training data containing 'address', 'city', 'province', and 'Result' columns\n",
        "training_data = pd.read_excel('/content/Training_data .xlsx')\n",
        "\n",
        "# Concatenate 'address', 'city', and 'province' columns into a single 'full_address' column\n",
        "training_data['full_address'] = training_data['address'].astype(str) + ', ' + training_data['city'].astype(str) + ', ' + training_data['province'].astype(str)\n",
        "API_Match = training_data['API']\n",
        "\n",
        "# Define the replacements for the address column\n",
        "replacements = {\n",
        "    r'\\bH\\b': 'House',\n",
        "    r'\\bh\\b': 'house',\n",
        "    r'\\bH(?![oO])\\b': 'House',\n",
        "    r'\\bh(?![oO])\\b': 'house',\n",
        "    r'\\bst\\b': 'Street',\n",
        "    r'\\bSt\\b': 'Street',\n",
        "    r'\\bST\\b': 'Street',\n",
        "    r'\\bST(?![rR])\\b': 'Street',\n",
        "    r'\\bSt(?![rR])\\b': 'Street',\n",
        "    r'\\bst(?![rR])\\b': 'Street'\n",
        "}\n",
        "\n",
        "# Function to perform replacements\n",
        "def replace_words(text):\n",
        "    if isinstance(text, str):\n",
        "        for pattern, replacement in replacements.items():\n",
        "            text = re.sub(pattern, replacement, text)\n",
        "        return text\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "# Apply replacements to each string in the 'full_address' column\n",
        "training_data['updated_address'] = training_data['full_address'].apply(replace_words)\n",
        "\n",
        "# Define feature extraction functions\n",
        "def extract_feature_1(text):\n",
        "    return 'Sector' in text or 'sector' in text or 'SECTOR' in text or 'Block' in text or 'BLOCK' in text or 'block' in text or 'House' in text or 'HOUSE' in text or 'house' in text or 'Street' in text or 'STREET' in text or 'street' in text or 'FLAT' in text or 'flat' in text or 'Flat' in text\n",
        "#'Sector|sector|SECTOR|Block|block|BLOCK|House|house|HOUSE|Street|street|STREET|Flat|flat|FLAT'\n",
        "\n",
        "def extract_feature_2(text):\n",
        "\n",
        "    return 'True' in API_Match\n",
        "\n",
        "def extract_feature_3(text):\n",
        "    return re.search(r'(House|house|HOUSE|H|no|NO|No|number|Number|n|N|Street|St|st|street|STREET) \\d', text) is not None\n",
        "\n",
        "# Extract features and add them as columns\n",
        "training_data['Featured_1'] = training_data['updated_address'].apply(extract_feature_1)\n",
        "training_data['Featured_2'] = training_data['updated_address'].apply(extract_feature_2)\n",
        "training_data['Featured_3'] = training_data['updated_address'].apply(extract_feature_3)\n",
        "\n",
        "# Use label encoding to convert textual labels to numerical values for the 'Result' column\n",
        "label_encoder = LabelEncoder()\n",
        "training_data['Result'] = label_encoder.fit_transform(training_data['Result'])\n",
        "\n",
        "# Drop unwanted columns\n",
        "training_data.drop(['order_id', 'province', 'city', 'address', 'status', 'updated_address', 'full_address'], axis=1, inplace=True)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = training_data.drop('Result', axis=1)\n",
        "y = training_data['Result']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    learning_rate=0.01,\n",
        "    n_estimators=500,\n",
        "    max_depth=300,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Define the hyperparameters to search\n",
        "param_grid = {\n",
        "    'max_depth': [3, 6],\n",
        "    'n_estimators': [100, 300],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'subsample': [0.7, 0.8],\n",
        "    'colsample_bytree': [0.7, 0.8]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_estimator.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the model\n",
        "y_pred_encoded = best_estimator.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_encoded)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred_encoded, average='weighted')\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "y_pred_prob = best_estimator.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Calculate R1-score\n",
        "recall = recall_score(y_test, y_pred_encoded, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"ROC AUC:\", roc_auc)\n",
        "print(\"R1-score:\", recall)\n",
        "\n",
        "# Save the trained model to a file\n",
        "model_filename = 'Address_Validation_Model_Updated.pkl'\n",
        "with open(model_filename, 'wb') as model_file:\n",
        "    pickle.dump(best_estimator, model_file)\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Training Completed and Model Saved as Address_Validator_Model.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5o3yytY6T0N"
      },
      "source": [
        "**Below Prediction Stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK41bWUCz5ZV",
        "outputId": "0edc18db-8798-4f4f-e511-377a7865d753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: Complete\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import regex as re\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define the replacements for the address column (same as in training code)\n",
        "replacements = {\n",
        "    r'\\bH\\b': 'House',\n",
        "    r'\\bh\\b': 'house',\n",
        "    r'\\bH(?![oO])\\b': 'House',\n",
        "    r'\\bh(?![oO])\\b': 'house',\n",
        "    r'\\bst\\b': 'Street',\n",
        "    r'\\bSt\\b': 'Street',\n",
        "    r'\\bST\\b': 'Street',\n",
        "    r'\\bST(?![rR])\\b': 'Street',\n",
        "    r'\\bSt(?![rR])\\b': 'Street',\n",
        "    r'\\bst(?![rR])\\b': 'Street'\n",
        "}\n",
        "# Function to perform replacements (same as in training code)\n",
        "def replace_words(text):\n",
        "    if isinstance(text, str):\n",
        "        for pattern, replacement in replacements.items():\n",
        "            text = re.sub(pattern, replacement, text)\n",
        "        return text\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "# Function to extract feature 2 (same as in training code)\n",
        "def extract_feature_2(text):\n",
        "    return 'True' in text\n",
        "\n",
        "# Define the input data\n",
        "address = 'Priceoye technology, sector h-12, NSTP NUST'\n",
        "province = 'Federal'\n",
        "city = 'Islamabad'\n",
        "API_Match = ''  # You need to set this value based on your API result\n",
        "\n",
        "# Concatenate 'address', 'province', and 'city' into a single string\n",
        "full_address = f\"{address}, {city}, {province}\"\n",
        "\n",
        "# Apply replacements to the 'full_address' string\n",
        "updated_address = replace_words(full_address)\n",
        "\n",
        "# Define feature extraction functions (similar to the training code)\n",
        "def extract_feature_1(text):\n",
        "    return 'Sector' in text or 'sector' in text or 'SECTOR' in text or 'Block' in text or 'BLOCK' in text or 'block' in text or 'House' in text or 'HOUSE' in text or 'house' in text or 'Street' in text or 'STREET' in text or 'street' in text or 'FLAT' in text or 'flat' in text or 'Flat' in text\n",
        "\n",
        "def extract_feature_3(text):\n",
        "    return re.search(r'(House|house|HOUSE|H|no|NO|No|number|Number|n|N|Street|St|st|street|STREET) \\d', text) is not None\n",
        "\n",
        "\n",
        "#API Code Below\n",
        "#API CODE\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Replace YOUR_API_KEY with your actual API key.\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "def validate_address(address):\n",
        "    url = f\"https://api.geoapify.com/v1/geocode/search?text={address}&limit=1&apiKey={API_KEY}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if data.get(\"features\"):\n",
        "                result = data[\"features\"][0]\n",
        "                latitude = result[\"geometry\"][\"coordinates\"][1]\n",
        "                longitude = result[\"geometry\"][\"coordinates\"][0]\n",
        "                return \"Y\", latitude, longitude\n",
        "            else:\n",
        "                return \"N\", None, None\n",
        "        else:\n",
        "            return \"N\", None, None\n",
        "    except requests.exceptions.RequestException:\n",
        "        return \"N\", None, None\n",
        "\n",
        "def translate_lat_long_to_address(latitude, longitude):\n",
        "    url = f\"https://api.geoapify.com/v1/geocode/reverse?lat={latitude}&lon={longitude}&apiKey={API_KEY}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if data.get(\"features\"):\n",
        "                result = data[\"features\"][0]\n",
        "                return result[\"properties\"][\"formatted\"]\n",
        "            else:\n",
        "                return None\n",
        "        else:\n",
        "            return None\n",
        "    except requests.exceptions.RequestException:\n",
        "        return None\n",
        "def process_api(address, province, city):\n",
        "  # Concatenate 'area' and 'city' fields with 'address' field\n",
        "  formatted_address = f'{address}, {province}, {city}'\n",
        "  # Apply the validate_address function to the formatted address and create the 'API_Output' variable\n",
        "  API_Output, _, _ = validate_address(formatted_address)\n",
        "  return API_Output\n",
        "\n",
        "# Replace 'YOUR_API_KEY' with the actual API key provided by Geoapify\n",
        "API_KEY = '00f15a2629b744fe9e2c1088c1d521db'\n",
        "API_Output = process_api(address, province, city)\n",
        "if (API_Output == \"Y\") and ((re.compile('House|house|HOUSE|H|no|NO|No|number|Number|n|N|Street|St|st|street|STREET').search(address) is not None) or (re.compile('House|house|HOUSE|H|no|NO|No|number|Number|n|N|Street|St|st|street|STREET \\d').search(address) is not None)):\n",
        "  API_Match = True\n",
        "else:\n",
        "  API_Match = False\n",
        "\n",
        "# Extract features\n",
        "featured_1 = extract_feature_1(updated_address)\n",
        "featured_2 = extract_feature_2(str(API_Match))\n",
        "featured_3 = extract_feature_3(updated_address)\n",
        "\n",
        "# Create a DataFrame with the extracted features\n",
        "input_data = pd.DataFrame({\n",
        "    'API': API_Match, # True or False\n",
        "    'Featured_1': [featured_1],\n",
        "    'Featured_2': [featured_2],\n",
        "    'Featured_3': [featured_3]\n",
        "})\n",
        "\n",
        "# Load the trained XGBoost model\n",
        "model_filename = 'Address_Validation_Model_Updated.joblib'  # Adjust the path as needed\n",
        "loaded_model = joblib.load(model_filename)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "y_pred_encoded = loaded_model.predict(input_data)\n",
        "\n",
        "# Inverse transform the predicted labels to get the original textual class labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(training_data['Result'])  # Ensure training_data is available from training code\n",
        "predicted_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "def decode(predicted_labels):\n",
        "  if predicted_labels==0:\n",
        "    return 'Complete'\n",
        "  else:\n",
        "    return 'Incomplete'\n",
        "\n",
        "\n",
        "\n",
        "print(\"Predicted Label:\", decode(predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below Is the Deployment Code**"
      ],
      "metadata": {
        "id": "6hamEEEqPUnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import regex as re\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define the replacements for the address column (same as in training code)\n",
        "replacements = {\n",
        "    r'\\bH\\b': 'House',\n",
        "    r'\\bh\\b': 'house',\n",
        "    r'\\bH(?![oO])\\b': 'House',\n",
        "    r'\\bh(?![oO])\\b': 'house',\n",
        "    r'\\bst\\b': 'Street',\n",
        "    r'\\bSt\\b': 'Street',\n",
        "    r'\\bST\\b': 'Street',\n",
        "    r'\\bST(?![rR])\\b': 'Street',\n",
        "    r'\\bSt(?![rR])\\b': 'Street',\n",
        "    r'\\bst(?![rR])\\b': 'Street'\n",
        "}\n",
        "\n",
        "# Function to perform replacements (same as in training code)\n",
        "def replace_words(text):\n",
        "    if isinstance(text, str):\n",
        "        for pattern, replacement in replacements.items():\n",
        "            text = re.sub(pattern, replacement, text)\n",
        "        return text\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "# Function to extract feature 2 (same as in training code)\n",
        "def extract_feature_2(text):\n",
        "    return 'True' in text\n",
        "\n",
        "# Load the trained XGBoost model\n",
        "model_filename = 'Address_Validation_Model_Updated.pkl'\n",
        "with open(model_filename, 'rb') as model_file:\n",
        "    loaded_model = pickle.load(model_file)\n",
        "\n",
        "# Label Encoder (same as in training code)\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(training_data['Result'])  # Ensure training_data is available from training code\n",
        "\n",
        "# Define a route for address validation and prediction\n",
        "@app.route('/validate_address', methods=['POST'])\n",
        "def validate_address():\n",
        "    try:\n",
        "        # Receive input data from the request\n",
        "        data = request.get_json()\n",
        "\n",
        "        # Extract data\n",
        "        address = data['address']\n",
        "        province = data['province']\n",
        "        city = data['city']\n",
        "\n",
        "        # Concatenate 'address', 'province', and 'city' into a single string\n",
        "        full_address = f\"{address}, {city}, {province}\"\n",
        "\n",
        "        # Apply replacements to the 'full_address' string\n",
        "        updated_address = replace_words(full_address)\n",
        "\n",
        "        # Perform address validation and feature extraction\n",
        "        # (You need to implement your address validation logic here)\n",
        "        API_Match = False  # You need to set this value based on your API result\n",
        "        featured_1 = extract_feature_1(updated_address)\n",
        "        featured_2 = extract_feature_2(str(API_Match))\n",
        "        featured_3 = extract_feature_3(updated_address)\n",
        "\n",
        "        # Create a DataFrame with the extracted features\n",
        "        input_data = pd.DataFrame({\n",
        "            'API': API_Match,  # True or False\n",
        "            'Featured_1': [featured_1],\n",
        "            'Featured_2': [featured_2],\n",
        "            'Featured_3': [featured_3]\n",
        "        })\n",
        "\n",
        "        # Make predictions using the loaded model\n",
        "        y_pred_encoded = loaded_model.predict(input_data)\n",
        "\n",
        "        # Inverse transform the predicted labels to get the original textual class labels\n",
        "        predicted_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "        # Define a decoding function to convert labels to meaningful values\n",
        "        def decode(predicted_labels):\n",
        "            if predicted_labels == 0:\n",
        "                return 'Complete'\n",
        "            else:\n",
        "                return 'Incomplete'\n",
        "\n",
        "        # Get the decoded prediction\n",
        "        prediction = decode(predicted_labels)\n",
        "\n",
        "        return jsonify({'prediction': prediction})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "ye4S6xACPZ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import flask\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "!pip install waitress\n",
        "import waitress\n",
        "from waitress import serve\n",
        "!pip install ngrok\n",
        "!pip install flask.ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "!pip install pyngrok\n",
        "!pip install --upgrade pyngrok\n",
        "import pyngrok\n",
        "import ngrok\n",
        "!pip install asyncio\n",
        "import asyncio\n",
        "import ngrok\n",
        "#from your_module import extract_feature_1, extract_feature_2, extract_feature_3, decode\n",
        "\n",
        "ngrok.set_auth_token('2WCC2lAMlA4EM93VzDtGVLTkL30_4Y66EVZYRMHbnoc61cmnM')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ngrok.connect(80, \"tcp\")\n",
        "# Print the public URL of the tunnel to the console.\n",
        "#print(tunnel.public_url)\n",
        "# Start an Ngrok tunnel to port 80.\n",
        "import subprocess\n",
        "# Run the 'netstat' command to check for port 80\n",
        "result = subprocess.run([\"netstat\", \"-an\"], capture_output=True, text=True, shell=True)\n",
        "# Check if port 80 is in the command output\n",
        "if \"80\" in result.stdout:\n",
        "    print(\"Port 80 is in use.\")\n",
        "else:\n",
        "    print(\"Port 80 is not in use.\")\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "  return render_template(\"index.html\")\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "  # Extract features from the request data\n",
        "  address = request.form[\"address\"]\n",
        "  province = request.form[\"province\"]\n",
        "  city = request.form[\"city\"]\n",
        "\n",
        "  # Load the trained XGBoost model\n",
        "  model_filename = 'Address_Validation_Model_Updated.pkl'\n",
        "  with open(model_filename, 'rb') as model_file:\n",
        "    loaded_model = pickle.load(model_file)\n",
        "\n",
        "  # Make predictions using the loaded model\n",
        "  input_data = pd.DataFrame({\n",
        "    \"API\": [True],\n",
        "    \"Featured_1\": [extract_feature_1(address)],\n",
        "    \"Featured_2\": [extract_feature_2(address)],\n",
        "    \"Featured_3\": [extract_feature_3(address)]\n",
        "  })\n",
        "\n",
        "  y_pred_encoded = loaded_model.predict(input_data)\n",
        "  predicted_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "  # Decode the predicted label\n",
        "  predicted_label = decode(predicted_labels)\n",
        "\n",
        "  # Return the predicted label as a JSON response\n",
        "  return jsonify({\"predicted_label\": predicted_label})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ukD1wP1y5ZPp",
        "outputId": "5af31863-6a1f-4a4c-9fbd-761b15636be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: waitress in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Collecting ngrok\n",
            "  Downloading ngrok-0.10.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-0.10.1\n",
            "Collecting flask.ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask.ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask.ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask.ngrok) (2.3.7)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask.ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask.ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask.ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask.ngrok) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask.ngrok) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask.ngrok) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask.ngrok) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask.ngrok) (2.1.3)\n",
            "Installing collected packages: flask.ngrok\n",
            "Successfully installed flask.ngrok-0.0.25\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.0.tar.gz (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.7/718.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-7.0.0-py3-none-any.whl size=21129 sha256=60a71a1f9c5d98736c753fb00fcaaa3cede48834bfd82c5d3ad4eff4b96b3821\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/29/7b/f64332aa7e5e88fbd56d4002185ae22dcdc83b35b3d1c2cbf5\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.0\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Collecting asyncio\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asyncio\n",
            "Successfully installed asyncio-3.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "asyncio"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Port 80 is not in use.\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://76f7-35-236-222-255.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Exception on / [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 2529, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1825, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/app.py\", line 1799, in dispatch_request\n",
            "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
            "  File \"<ipython-input-32-534e38c63f3a>\", line 43, in index\n",
            "    return render_template(\"index.html\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/templating.py\", line 146, in render_template\n",
            "    template = app.jinja_env.get_or_select_template(template_name_or_list)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jinja2/environment.py\", line 1081, in get_or_select_template\n",
            "    return self.get_template(template_name_or_list, parent, globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jinja2/environment.py\", line 1010, in get_template\n",
            "    return self._load_template(name, globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jinja2/environment.py\", line 969, in _load_template\n",
            "    template = self.loader.load(self, name, self.make_globals(globals))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jinja2/loaders.py\", line 126, in load\n",
            "    source, filename, uptodate = self.get_source(environment, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/templating.py\", line 62, in get_source\n",
            "    return self._get_source_fast(environment, template)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask/templating.py\", line 98, in _get_source_fast\n",
            "    raise TemplateNotFound(template)\n",
            "jinja2.exceptions.TemplateNotFound: index.html\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2023 10:20:05] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [02/Oct/2023 10:20:07] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-mIHJAXUeQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddfecf8-fcd8-4af7-8eb1-1b9bb520db8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfgLBt5egfLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56de054a-4cbc-4c03-c206-a866dc006fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Address_Validation_Updated\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Address_Validation_Updated/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ORjORc-hx2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eaf3a83-f99e-454e-fabc-671fdc54fe68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Address_Validation_Updated/app.py\", line 5, in <module>\n",
            "    import waitress\n",
            "ModuleNotFoundError: No module named 'waitress'\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etCSU9i-Amw"
      },
      "source": [
        "**Deployment Stuff Below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pECaohxmXNzG"
      },
      "outputs": [],
      "source": [
        "#!python app.py --port"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G93ALpLBPFvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "7d82f768-a88c-41b4-856e-7bf428d144a2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-0a94de171994>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    http://localhost:8080\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "http://localhost:8080"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7n8QNmkU3bH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}